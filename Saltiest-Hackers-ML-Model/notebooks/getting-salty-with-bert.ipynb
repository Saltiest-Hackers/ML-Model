{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# cleaning of html tags\n",
    "from bs4 import BeautifulSoup\n",
    "# stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# tokenization\n",
    "# https://pypi.org/project/tokenizers/\n",
    "from tokenizers import (ByteLevelBPETokenizer,\n",
    "                            CharBPETokenizer,\n",
    "                            SentencePieceBPETokenizer,\n",
    "                            BertWordPieceTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/btr-dev/wrkspc/prj/salty-hackers/ML-Model/Saltiest-Hackers-ML-Model\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  models  notebooks  references  src\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/raw/gcp-bq-full/1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIR = 'data/raw/gcp-bq-full/'\n",
    "\n",
    "FILES = [ str(f) for f in list(range(1,18))]\n",
    "DIR+FILES[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>dead</th>\n",
       "      <th>by</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>parent</th>\n",
       "      <th>descendants</th>\n",
       "      <th>ranking</th>\n",
       "      <th>deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I started to write a C++ template class that w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cpeterso</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.338489e+09</td>\n",
       "      <td>2012-05-31 18:32:12 UTC</td>\n",
       "      <td>comment</td>\n",
       "      <td>4049595</td>\n",
       "      <td>4049139.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&amp;gt; I&amp;#x27;m guessing over $200B of Amazon&amp;#x...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fweespeech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.498437e+09</td>\n",
       "      <td>2017-06-26 00:33:02 UTC</td>\n",
       "      <td>comment</td>\n",
       "      <td>14633082</td>\n",
       "      <td>14632856.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I don&amp;#x27;t know what to say - that just soun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrisseaton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.552875e+09</td>\n",
       "      <td>2019-03-18 02:17:05 UTC</td>\n",
       "      <td>comment</td>\n",
       "      <td>19418238</td>\n",
       "      <td>19418216.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>if you&amp;#x27;re going to make the accusation th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aloha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.515732e+09</td>\n",
       "      <td>2018-01-12 04:37:28 UTC</td>\n",
       "      <td>comment</td>\n",
       "      <td>16130436</td>\n",
       "      <td>16130413.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>With the current trend of simplifying your int...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>drill_sarge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.382406e+09</td>\n",
       "      <td>2013-10-22 01:40:09 UTC</td>\n",
       "      <td>comment</td>\n",
       "      <td>6589315</td>\n",
       "      <td>6588825.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  title  url                                               text dead  \\\n",
       "0   NaN  NaN  I started to write a C++ template class that w...  NaN   \n",
       "1   NaN  NaN  &gt; I&#x27;m guessing over $200B of Amazon&#x...  NaN   \n",
       "2   NaN  NaN  I don&#x27;t know what to say - that just soun...  NaN   \n",
       "3   NaN  NaN  if you&#x27;re going to make the accusation th...  NaN   \n",
       "4   NaN  NaN  With the current trend of simplifying your int...  NaN   \n",
       "\n",
       "            by  score          time                timestamp     type  \\\n",
       "0     cpeterso    NaN  1.338489e+09  2012-05-31 18:32:12 UTC  comment   \n",
       "1   fweespeech    NaN  1.498437e+09  2017-06-26 00:33:02 UTC  comment   \n",
       "2  chrisseaton    NaN  1.552875e+09  2019-03-18 02:17:05 UTC  comment   \n",
       "3        Aloha    NaN  1.515732e+09  2018-01-12 04:37:28 UTC  comment   \n",
       "4  drill_sarge    NaN  1.382406e+09  2013-10-22 01:40:09 UTC  comment   \n",
       "\n",
       "         id      parent  descendants  ranking deleted  \n",
       "0   4049595   4049139.0          NaN      NaN     NaN  \n",
       "1  14633082  14632856.0          NaN      NaN     NaN  \n",
       "2  19418238  19418216.0          NaN      NaN     NaN  \n",
       "3  16130436  16130413.0          NaN      NaN     NaN  \n",
       "4   6589315   6588825.0          NaN      NaN     NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DIR+FILES[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SO after a few days of reading I think I finally got it\n",
    "I will start by creating a training set. I will loop over the collected data, which is comprised of a shuffled set of all comments from the Hacker News website, process the text and select for a few requirements:\n",
    "- We should exclude comments with low word counts so that the final model doesn't tune its self to any word in particular\n",
    "- We should aim for the highest amount of unique words possible\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrub(doc):\n",
    "    return re.sub(r'[^A-Za-z\\s]', '', str(doc))\n",
    "\n",
    "def word_frequencies(df):\n",
    "    \"\"\"Returns a dict with key, value pair of word frequencies in descending order\n",
    "    \n",
    "    Args:\n",
    "    -----\n",
    "    df - pandas.DataFrame object\n",
    "    \"\"\"\n",
    "    ngram_vectorizer = CountVectorizer(analyzer='word',\n",
    "                                       ngram_range=(1, 1),\n",
    "                                       min_df=1)\n",
    "    \n",
    "    X = ngram_vectorizer.fit_transform(df['text'])    \n",
    "    vocab = ngram_vectorizer.get_feature_names()\n",
    "    counts = X.sum(axis=0).A1\n",
    "    \n",
    "    freqs = dict(Counter(dict(zip(vocab, counts))))    \n",
    "    return freqs\n",
    "\n",
    "def process_text(df):\n",
    "    # only those comments with not null values\n",
    "    df = df.loc[df['type'] == 'comment'][['text']]\n",
    "    df = df.dropna()    \n",
    "    # clean the text using bs4\n",
    "    df['text'] = df['text'].apply(lambda x: BeautifulSoup(x).get_text())\n",
    "    # regex remove all non-letters && to lower\n",
    "    df['text'] = df['text'].apply(scrub)\n",
    "    df['text'] = df['text'].str.lower()\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_stops(df):\n",
    "    # start with NLTK stopwords\n",
    "    stop_words = list(nltk.corpus.stopwords.words('english'))\n",
    "    \n",
    "    # word frequencies for the batch\n",
    "    print('Determining word frequencies')\n",
    "    freqs = word_frequencies(df)\n",
    "    \n",
    "    # rare words\n",
    "    rare = list({key: value for key, value in freqs.items() if value < 2}.keys())\n",
    "    \n",
    "    # common words - occur at a frequency greater than the total number of observations\n",
    "    common = list(freqs.keys())[:15]\n",
    "    \n",
    "    # add the common and rare words to the set\n",
    "    stop_words = set(stop_words + common + rare)\n",
    "    \n",
    "    # use regex for stopword removal\n",
    "    print(f'Removing stopwords: {len(stop_words)} total')\n",
    "#     pat = r'\\b(?:{})\\b'.format('|'.join(stop_words))\n",
    "    \n",
    "    df['text'] = df['text'].apply(lambda x: ' '. \\\n",
    "                  join([word for word in x.split() if word not in (stop_words)]))\n",
    "#     df['text'] = df['text'].str.replace(r'\\s+', ' ')\n",
    "    \n",
    "    # retaining comments with 30 or more words\n",
    "    df = df.loc[df['text'].apply(lambda x: len(str(x).split(\" \"))).values > 30]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  models  notebooks  references  src\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/btr-dev/res/miniconda3/envs/salty-model/lib/python3.7/site-packages/bs4/__init__.py:314: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "/home/btr-dev/res/miniconda3/envs/salty-model/lib/python3.7/site-packages/bs4/__init__.py:314: UserWarning: \"b'..'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "df1 = process_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 10.7 µs\n",
      "Determining word frequencies\n",
      "Removing stopwords: 807214 total\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>started write c template class would implement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im guessing b amazons b valuation aws amazons ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>im sure many variations problem worked like mc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>much doubt would suicide itd economic inconven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>overall also problem physical retail germans l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319831</th>\n",
       "      <td>ive got commend bitfury levis bitcoinjust ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319841</th>\n",
       "      <td>ive worked home eight months bedroom wife two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319852</th>\n",
       "      <td>diligent robotics austin tx robotics software ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319855</th>\n",
       "      <td>least fear world destroying ai based upon real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319856</th>\n",
       "      <td>leads elegant conflicts abortion going save li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text\n",
       "0        started write c template class would implement...\n",
       "1        im guessing b amazons b valuation aws amazons ...\n",
       "10       im sure many variations problem worked like mc...\n",
       "24       much doubt would suicide itd economic inconven...\n",
       "25       overall also problem physical retail germans l...\n",
       "...                                                    ...\n",
       "1319831  ive got commend bitfury levis bitcoinjust ever...\n",
       "1319841  ive worked home eight months bedroom wife two ...\n",
       "1319852  diligent robotics austin tx robotics software ...\n",
       "1319855  least fear world destroying ai based upon real...\n",
       "1319856  leads elegant conflicts abortion going save li...\n",
       "\n",
       "[358500 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "df2 = remove_stops(df1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = dict(freqs.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "(list(freqs.values()).sort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'to',\n",
       " 'of',\n",
       " 'and',\n",
       " 'is',\n",
       " 'that',\n",
       " 'in',\n",
       " 'it',\n",
       " 'you',\n",
       " 'for',\n",
       " 'be',\n",
       " 'on',\n",
       " 'are',\n",
       " 'not',\n",
       " 'with']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common = list(freqs.keys())[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-468b3de40890>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcommon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-92-468b3de40890>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcommon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "common = list({key: value for key, value in freqs.items() if value < list(freqs.values())[14]}.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertWordPieceTokenizer(\"data/external/vocab/bert-base-uncased-vocab.txt\", lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I started to write a C++ template class that would implement strongly-typed ints (so Celsius and Fahrenheit types could behave like ints, but have distinct types).I gave up after this \"simple\" idea approached 200 lines of code implementing all the operator overloads. I guess the lesson is that primitives are complex, even if you just want to give them a new name. Also, the expression int/int produces an int, but what should the expression FahrenheitInt/FahrenheitInt produce? A unitless int? A FahrenheitInt?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = BeautifulSoup(df['text'][0]).get_text()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub(r'[^A-Za-z\\s]', '', df['text'][0]).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'started',\n",
       " 'to',\n",
       " 'write',\n",
       " 'a',\n",
       " 'c',\n",
       " 'template',\n",
       " 'class',\n",
       " 'that',\n",
       " 'would',\n",
       " 'implement',\n",
       " 'stronglytyped',\n",
       " 'ints',\n",
       " 'so',\n",
       " 'celsius',\n",
       " 'and',\n",
       " 'fahrenheit',\n",
       " 'types',\n",
       " 'could',\n",
       " 'behave',\n",
       " 'like',\n",
       " 'ints',\n",
       " 'but',\n",
       " 'have',\n",
       " 'distinct',\n",
       " 'typespi',\n",
       " 'gave',\n",
       " 'up',\n",
       " 'after',\n",
       " 'this',\n",
       " 'simple',\n",
       " 'idea',\n",
       " 'approached',\n",
       " 'lines',\n",
       " 'of',\n",
       " 'code',\n",
       " 'implementing',\n",
       " 'all',\n",
       " 'the',\n",
       " 'operator',\n",
       " 'overloads',\n",
       " 'i',\n",
       " 'guess',\n",
       " 'the',\n",
       " 'lesson',\n",
       " 'is',\n",
       " 'that',\n",
       " 'primitives',\n",
       " 'are',\n",
       " 'complex',\n",
       " 'even',\n",
       " 'if',\n",
       " 'you',\n",
       " 'just',\n",
       " 'want',\n",
       " 'to',\n",
       " 'give',\n",
       " 'them',\n",
       " 'a',\n",
       " 'new',\n",
       " 'name',\n",
       " 'also',\n",
       " 'the',\n",
       " 'expression',\n",
       " 'iintinti',\n",
       " 'produces',\n",
       " 'an',\n",
       " 'int',\n",
       " 'but',\n",
       " 'what',\n",
       " 'should',\n",
       " 'the',\n",
       " 'expression',\n",
       " 'ifahrenheitintfahrenheitinti',\n",
       " 'produce',\n",
       " 'a',\n",
       " 'unitless',\n",
       " 'int',\n",
       " 'a',\n",
       " 'fahrenheitint']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tokenize(text, pattern = '\\s', gaps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          I started to write a C++ template class that w...\n",
       "1          &gt; I&#x27;m guessing over $200B of Amazon&#x...\n",
       "2          I don&#x27;t know what to say - that just soun...\n",
       "4          With the current trend of simplifying your int...\n",
       "10         I&#x27;m sure there are many variations to thi...\n",
       "                                 ...                        \n",
       "1319844    I still get a small thrill from stepping onto ...\n",
       "1319852    Diligent Robotics | Austin, TX | Robotics Soft...\n",
       "1319854    Wait, were you an OA customer? Tell us more!<p...\n",
       "1319855    At least the fear of a world destroying AI is ...\n",
       "1319856    This leads to such elegant conflicts as: what ...\n",
       "Name: text, Length: 654405, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['text'].apply(lambda x: len(str(x).split(\" \"))).values > 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          I started to write a C++ template class that w...\n",
       "1          &gt; I&#x27;m guessing over $200B of Amazon&#x...\n",
       "2          I don&#x27;t know what to say - that just soun...\n",
       "3          if you&#x27;re going to make the accusation th...\n",
       "4          With the current trend of simplifying your int...\n",
       "                                 ...                        \n",
       "1319853    Good, get rid of duplicate products, makes sense.\n",
       "1319854    Wait, were you an OA customer? Tell us more!<p...\n",
       "1319855    At least the fear of a world destroying AI is ...\n",
       "1319856    This leads to such elegant conflicts as: what ...\n",
       "1319857                                                  NaN\n",
       "Name: text, Length: 1319858, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i started to write a c++ template class that would implement strongly-typed ints (so celsius and fahrenheit types could behave like ints, but have distinct types).<p>i gave up after this \"simple\" idea approached 200 lines of code implementing all the operator overloads. i guess the lesson is that primitives are complex, even if you just want to give them a new name. also, the expression <i>int/int</i> produces an int, but what should the expression <i>fahrenheitint/fahrenheitint</i> produce? a unitless int? a fahrenheitint?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I started to write a C++ template class that would implement strongly-typed ints (so Celsius and Fahrenheit types could behave like ints, but have distinct types).I gave up after this \"simple\" idea approached 200 lines of code implementing all the operator overloads. I guess the lesson is that primitives are complex, even if you just want to give them a new name. Also, the expression int/int produces an int, but what should the expression FahrenheitInt/FahrenheitInt produce? A unitless int? A FahrenheitInt?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salty-model",
   "language": "python",
   "name": "salty-mle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
