{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# cleaning of html tags\n",
    "from bs4 import BeautifulSoup\n",
    "# stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# tokenization\n",
    "# https://pypi.org/project/tokenizers/\n",
    "from tokenizers import (ByteLevelBPETokenizer,\n",
    "                            CharBPETokenizer,\n",
    "                            SentencePieceBPETokenizer,\n",
    "                            BertWordPieceTokenizer)\n",
    "\n",
    "# VADER\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "------\n",
    "## 1\n",
    "[ ] rerun code retain ids\n",
    "\n",
    "[ ] collect stats on difference in outcomes between no processing and post processing\n",
    "\n",
    "[ ] function for getting scores on 100k comments & collecting outcomes stats\n",
    "\n",
    "[ ] quick graphs\n",
    "\n",
    "-------------------\n",
    "\n",
    "## 2\n",
    "\n",
    "[ ] keep ID\n",
    "\n",
    "[ ] function for iterating through data and keeping the most extreme examples for both ends of spectrum\n",
    "\n",
    "- 50k comments --> 25k most positive && 25k most negative\n",
    "\n",
    "[ ] packaging existing functions\n",
    "\n",
    "[ ] README\n",
    "\n",
    "[ ] TBC..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/btr-dev/wrkspc/prj/salty-hackers/ML-Model/Saltiest-Hackers-ML-Model\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  models  notebooks  references  src\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/raw/gcp-bq-full/1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIR = 'data/raw/gcp-bq-full/'\n",
    "\n",
    "FILES = [ str(f) for f in list(range(1,18))]\n",
    "DIR+FILES[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>dead</th>\n",
       "      <th>by</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>parent</th>\n",
       "      <th>descendants</th>\n",
       "      <th>ranking</th>\n",
       "      <th>deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I started to write a C++ template class that w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cpeterso</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.338489e+09</td>\n",
       "      <td>2012-05-31 18:32:12 UTC</td>\n",
       "      <td>comment</td>\n",
       "      <td>4049595</td>\n",
       "      <td>4049139.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&amp;gt; I&amp;#x27;m guessing over $200B of Amazon&amp;#x...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fweespeech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.498437e+09</td>\n",
       "      <td>2017-06-26 00:33:02 UTC</td>\n",
       "      <td>comment</td>\n",
       "      <td>14633082</td>\n",
       "      <td>14632856.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I don&amp;#x27;t know what to say - that just soun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrisseaton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.552875e+09</td>\n",
       "      <td>2019-03-18 02:17:05 UTC</td>\n",
       "      <td>comment</td>\n",
       "      <td>19418238</td>\n",
       "      <td>19418216.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>if you&amp;#x27;re going to make the accusation th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aloha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.515732e+09</td>\n",
       "      <td>2018-01-12 04:37:28 UTC</td>\n",
       "      <td>comment</td>\n",
       "      <td>16130436</td>\n",
       "      <td>16130413.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>With the current trend of simplifying your int...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>drill_sarge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.382406e+09</td>\n",
       "      <td>2013-10-22 01:40:09 UTC</td>\n",
       "      <td>comment</td>\n",
       "      <td>6589315</td>\n",
       "      <td>6588825.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  title  url                                               text dead  \\\n",
       "0   NaN  NaN  I started to write a C++ template class that w...  NaN   \n",
       "1   NaN  NaN  &gt; I&#x27;m guessing over $200B of Amazon&#x...  NaN   \n",
       "2   NaN  NaN  I don&#x27;t know what to say - that just soun...  NaN   \n",
       "3   NaN  NaN  if you&#x27;re going to make the accusation th...  NaN   \n",
       "4   NaN  NaN  With the current trend of simplifying your int...  NaN   \n",
       "\n",
       "            by  score          time                timestamp     type  \\\n",
       "0     cpeterso    NaN  1.338489e+09  2012-05-31 18:32:12 UTC  comment   \n",
       "1   fweespeech    NaN  1.498437e+09  2017-06-26 00:33:02 UTC  comment   \n",
       "2  chrisseaton    NaN  1.552875e+09  2019-03-18 02:17:05 UTC  comment   \n",
       "3        Aloha    NaN  1.515732e+09  2018-01-12 04:37:28 UTC  comment   \n",
       "4  drill_sarge    NaN  1.382406e+09  2013-10-22 01:40:09 UTC  comment   \n",
       "\n",
       "         id      parent  descendants  ranking deleted  \n",
       "0   4049595   4049139.0          NaN      NaN     NaN  \n",
       "1  14633082  14632856.0          NaN      NaN     NaN  \n",
       "2  19418238  19418216.0          NaN      NaN     NaN  \n",
       "3  16130436  16130413.0          NaN      NaN     NaN  \n",
       "4   6589315   6588825.0          NaN      NaN     NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DIR+FILES[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SO after a few days of reading I think I finally got it\n",
    "I will start by creating a training set. I will loop over the collected data, which is comprised of a shuffled set of all comments from the Hacker News website, process the text and select for a few requirements:\n",
    "- We should exclude comments with low word counts so that the final model doesn't tune its self to any word in particular\n",
    "- We should aim for the highest amount of unique words possible\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrub(doc):\n",
    "    return re.sub(r'[^A-Za-z\\s]', '', str(doc))\n",
    "\n",
    "def word_frequencies(df):\n",
    "    \"\"\"Returns a dict with key, value pair of word frequencies in descending order\n",
    "    \n",
    "    Args:\n",
    "    -----\n",
    "    df - pandas.DataFrame object\n",
    "    \"\"\"\n",
    "    ngram_vectorizer = CountVectorizer(analyzer='word',\n",
    "                                       ngram_range=(1, 1),\n",
    "                                       min_df=1)\n",
    "    \n",
    "    X = ngram_vectorizer.fit_transform(df['text'])    \n",
    "    vocab = ngram_vectorizer.get_feature_names()\n",
    "    counts = X.sum(axis=0).A1\n",
    "    \n",
    "    freqs = dict(Counter(dict(zip(vocab, counts))))    \n",
    "    return freqs\n",
    "\n",
    "def process_text(df):\n",
    "    # only those comments with not null values\n",
    "    df = df.loc[df['type'] == 'comment'][['text']]\n",
    "    df = df.dropna()    \n",
    "    # clean the text using bs4\n",
    "    df['text'] = df['text'].apply(lambda x: BeautifulSoup(x).get_text())\n",
    "    # regex remove all non-letters && to lower\n",
    "    df['text'] = df['text'].apply(scrub)\n",
    "    df['text'] = df['text'].str.lower()\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_stops(df):\n",
    "    # start with NLTK stopwords\n",
    "    stop_words = list(nltk.corpus.stopwords.words('english'))\n",
    "    \n",
    "    # word frequencies for the batch\n",
    "    print('Determining word frequencies')\n",
    "    freqs = word_frequencies(df)\n",
    "    \n",
    "    # rare words\n",
    "    rare = list({key: value for key, value in freqs.items() if value < 2}.keys())\n",
    "    \n",
    "    # common words - occur at a frequency greater than the total number of observations\n",
    "    common = list(freqs.keys())[:15]\n",
    "    \n",
    "    # add the common and rare words to the set\n",
    "    stop_words = set(stop_words + common + rare)\n",
    "    \n",
    "    # use regex for stopword removal\n",
    "    print(f'Removing stopwords: {len(stop_words)} total')\n",
    "#     pat = r'\\b(?:{})\\b'.format('|'.join(stop_words))\n",
    "    \n",
    "    df['text'] = df['text'].apply(lambda x: ' '. \\\n",
    "                  join([word for word in x.split() if word not in (stop_words)]))\n",
    "#     df['text'] = df['text'].str.replace(r'\\s+', ' ')\n",
    "    \n",
    "    # retaining comments with 30 or more words\n",
    "    df = df.loc[df['text'].apply(lambda x: len(str(x).split(\" \"))).values > 30]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  models  notebooks  references  src\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/btr-dev/res/miniconda3/envs/salty-model/lib/python3.7/site-packages/bs4/__init__.py:314: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "/home/btr-dev/res/miniconda3/envs/salty-model/lib/python3.7/site-packages/bs4/__init__.py:314: UserWarning: \"b'..'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "df1 = process_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 10.7 µs\n",
      "Determining word frequencies\n",
      "Removing stopwords: 807214 total\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>started write c template class would implement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im guessing b amazons b valuation aws amazons ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>im sure many variations problem worked like mc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>much doubt would suicide itd economic inconven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>overall also problem physical retail germans l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319831</th>\n",
       "      <td>ive got commend bitfury levis bitcoinjust ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319841</th>\n",
       "      <td>ive worked home eight months bedroom wife two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319852</th>\n",
       "      <td>diligent robotics austin tx robotics software ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319855</th>\n",
       "      <td>least fear world destroying ai based upon real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319856</th>\n",
       "      <td>leads elegant conflicts abortion going save li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text\n",
       "0        started write c template class would implement...\n",
       "1        im guessing b amazons b valuation aws amazons ...\n",
       "10       im sure many variations problem worked like mc...\n",
       "24       much doubt would suicide itd economic inconven...\n",
       "25       overall also problem physical retail germans l...\n",
       "...                                                    ...\n",
       "1319831  ive got commend bitfury levis bitcoinjust ever...\n",
       "1319841  ive worked home eight months bedroom wife two ...\n",
       "1319852  diligent robotics austin tx robotics software ...\n",
       "1319855  least fear world destroying ai based upon real...\n",
       "1319856  leads elegant conflicts abortion going save li...\n",
       "\n",
       "[358500 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "df2 = remove_stops(df1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I started to write a C++ template class that would implement strongly-typed ints (so Celsius and Fahrenheit types could behave like ints, but have distinct types).<p>I gave up after this \"simple\" idea approached 200 lines of code implementing all the operator overloads. I guess the lesson is that primitives are complex, even if you just want to give them a new name. Also, the expression <i>int/int</i> produces an int, but what should the expression <i>FahrenheitInt/FahrenheitInt</i> produce? A unitless int? A FahrenheitInt?',\n",
       "       '&gt; I&#x27;m guessing over $200B of Amazon&#x27;s $475B valuation is from AWS and Amazon&#x27;s subsidiaries. They have [small] stakes in some companies too. To be fair, the subsidiaries are peanuts^ (let&#x27;s be generous and give them a combined value of $10B).<p>I just believe (rightly or wrongly) that Amazon&#x27;s customers are more price sensitive that is commonly believed and the merry-go-round of constant reinvestment isn&#x27;t going to be something that can be stopped for that reason. I always thought Amazon was fairly valued around $300-400&#x2F;share and pretty much dumped all my stock in Amazon accordingly.<p>Maybe I&#x27;m wrong but I have a suspicion I&#x27;m not.<p>Look at Alphabet&#x27;s financials vs. Googles and I think you&#x27;ll find one of these seems just a much more reasonable valuation than the other at ~$1000&#x2F;share.',\n",
       "       'I don&#x27;t know what to say - that just sounds like normal method calls to me. Why do we need the term &#x27;message passing&#x27; on top of that, which seems to additionally confuse people around synchronous or not?',\n",
       "       'if you&#x27;re going to make the accusation that they&#x27;re lying, at least provide a source - near as I can tell they are being as transparent as is reasonable.',\n",
       "       'With the current trend of simplifying your interface graphics about 90% of this could be made in MS Paint. Also applies to Windows 8 and to some extend to desktops like GNOME.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = df['text'][:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['started write c template class would implement stronglytyped ints celsius fahrenheit types could behave like ints distinct typesi gave simple idea approached lines code implementing operator overloads guess lesson primitives complex even want give new name also expression intint produces int expression produce unitless int',\n",
       "       'im guessing b amazons b valuation aws amazons subsidiaries small stakes companies fair subsidiaries peanuts lets generous give combined value bi believe rightly wrongly amazons customers price sensitive commonly believed merrygoround constant reinvestment isnt going something stopped reason always thought amazon fairly valued around share pretty much dumped stock amazon accordinglymaybe im wrong suspicion im notlook alphabets financials vs googles think youll find one seems much reasonable valuation share',\n",
       "       'im sure many variations problem worked like mckenzie sp roughly picture pushup except every muscle body completely relaxed aside upper arms youre sort passively spine slowly repeatedly feel good many cycles day care careful get bed morning discs full water youre susceptible injury time',\n",
       "       'much doubt would suicide itd economic inconvenience even cause hell freeze stock holders even loss held companies rarely choose good public good stockholders unless given fiscal incentives tax increases tax become wealthy bill gates make nonprofit enormous wealth',\n",
       "       'overall also problem physical retail germans lot shopping online usually issue paying ccpaypal often getting prepaid cc thati living germany stand observation people credit card paypal luckily offers sepa direct debit even though many consider paypal reasons topic workaround particularly due fact quick online sepa payment schemes involve giving third party access banking account difficult see potential problems sofortberweisung ever breach theres real possibility data could used trigger massive amounts fraudulent money security nightmare nobody use offer sepa direct debit'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester2 = df2['text'][:5].values\n",
    "tester2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Collect stats on differences in outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.951, 'pos': 0.049, 'compound': 0.4098}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores(tester[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.917, 'pos': 0.083, 'compound': 0.4215}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores(tester2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salty-model",
   "language": "python",
   "name": "salty-mle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
